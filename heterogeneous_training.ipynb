{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/batu-el/understanding-inductive-biases-of-gnns/blob/main/notebooks/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVe55J-aw7aC"
   },
   "outputs": [],
   "source": [
    "# Combining Attention values across heads - Avg\n",
    "# Combining Attention values across layers - Matrix Multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRR5bUiLRZ5a"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95820,
     "status": "ok",
     "timestamp": 1714340656785,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "JLx8ARPERaaB",
    "outputId": "39a34a44-a10f-4423-81a8-ca4638185152",
    "ExecuteTime": {
     "end_time": "2025-03-22T18:41:25.283650Z",
     "start_time": "2025-03-22T18:39:47.456833Z"
    }
   },
   "source": [
    "!pip install dgl torch_geometric torch\n",
    "\n",
    "# Install required python libraries\n",
    "import os\n",
    "\n",
    "# Install PyTorch Geometric and other libraries\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(\"Installing PyTorch Geometric\")\n",
    "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "    !pip install -q torch-geometric\n",
    "    print(\"Installing other libraries\")\n",
    "    !pip install networkx\n",
    "    !pip install lovely-tensors"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl\n",
      "  Downloading dgl-2.2.1-cp311-cp311-win_amd64.whl.metadata (595 bytes)\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting numpy>=1.14.0 (from dgl)\n",
      "  Downloading numpy-2.2.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scipy>=1.1.0 (from dgl)\n",
      "  Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting networkx>=2.1 (from dgl)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (2.32.3)\n",
      "Collecting tqdm (from dgl)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (7.0.0)\n",
      "Collecting torchdata>=0.5.0 (from dgl)\n",
      "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pandas (from dgl)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Using cached aiohttp-3.11.14-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting fsspec (from torch_geometric)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
      "Collecting pyparsing (from torch_geometric)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Using cached multidict-6.2.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric)\n",
      "  Using cached propcache-0.3.0-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from pandas->dgl) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->dgl)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->dgl)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from tqdm->dgl) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
      "Downloading dgl-2.2.1-cp311-cp311-win_amd64.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 5.0/5.3 MB 27.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 25.0 MB/s eta 0:00:00\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 28.2 MB/s eta 0:00:00\n",
      "Downloading torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 7.3/204.2 MB 41.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 15.2/204.2 MB 38.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 22.8/204.2 MB 37.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 29.4/204.2 MB 35.1 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 35.9/204.2 MB 34.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 41.9/204.2 MB 33.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 46.7/204.2 MB 32.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 53.5/204.2 MB 31.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 59.5/204.2 MB 31.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 67.9/204.2 MB 32.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 74.7/204.2 MB 32.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 80.0/204.2 MB 31.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 86.2/204.2 MB 31.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 92.8/204.2 MB 31.7 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 100.7/204.2 MB 32.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 108.8/204.2 MB 32.3 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 116.1/204.2 MB 32.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 123.7/204.2 MB 32.6 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 131.6/204.2 MB 33.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 140.5/204.2 MB 33.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 149.9/204.2 MB 33.8 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 160.7/204.2 MB 34.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 171.4/204.2 MB 35.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 181.4/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.3/204.2 MB 35.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.1/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.4/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 35.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.2/204.2 MB 29.7 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading numpy-2.2.4-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 8.1/12.9 MB 41.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 36.9 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.5/41.2 MB 26.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.2/41.2 MB 23.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 16.3/41.2 MB 25.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 23.9/41.2 MB 28.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 30.9/41.2 MB 29.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/41.2 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.2/41.2 MB 28.5 MB/s eta 0:00:00\n",
      "Downloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
      "Using cached aiohttp-3.11.14-cp311-cp311-win_amd64.whl (443 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.2.0-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Using cached propcache-0.3.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Installing collected packages: pytz, mpmath, tzdata, tqdm, sympy, pyparsing, propcache, numpy, networkx, multidict, fsspec, frozenlist, filelock, aiohappyeyeballs, yarl, torch, scipy, pandas, aiosignal, torchdata, aiohttp, torch_geometric, dgl\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 dgl-2.2.1 filelock-3.18.0 frozenlist-1.5.0 fsspec-2025.3.0 mpmath-1.3.0 multidict-6.2.0 networkx-3.4.2 numpy-2.2.4 pandas-2.2.3 propcache-0.3.0 pyparsing-3.2.1 pytz-2025.1 scipy-1.15.2 sympy-1.13.1 torch-2.6.0 torch_geometric-2.6.1 torchdata-0.11.0 tqdm-4.67.1 tzdata-2025.1 yarl-1.18.3\n",
      "Installing PyTorch Geometric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing other libraries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (3.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lovely-tensors\n",
      "  Downloading lovely_tensors-0.1.18-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-tensors) (2.6.0)\n",
      "Collecting lovely-numpy>=0.2.13 (from lovely-tensors)\n",
      "  Downloading lovely_numpy-0.2.13-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-numpy>=0.2.13->lovely-tensors) (2.2.4)\n",
      "Collecting fastcore (from lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Downloading fastcore-1.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: ipython in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-numpy>=0.2.13->lovely-tensors) (9.0.2)\n",
      "Collecting matplotlib (from lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from sympy==1.13.1->torch->lovely-tensors) (1.3.0)\n",
      "Requirement already satisfied: packaging in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from fastcore->lovely-numpy>=0.2.13->lovely-tensors) (24.2)\n",
      "Requirement already satisfied: colorama in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from jinja2->torch->lovely-tensors) (3.0.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Using cached fonttools-4.56.0-cp311-cp311-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors)\n",
      "  Using cached pillow-11.1.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (2.9.0.post0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from jedi>=0.16->ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from stack_data->ipython->lovely-numpy>=0.2.13->lovely-tensors) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from stack_data->ipython->lovely-numpy>=0.2.13->lovely-tensors) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from stack_data->ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.2.3)\n",
      "Downloading lovely_tensors-0.1.18-py3-none-any.whl (19 kB)\n",
      "Downloading lovely_numpy-0.2.13-py3-none-any.whl (24 kB)\n",
      "Downloading fastcore-1.8.0-py3-none-any.whl (78 kB)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 5.2/8.1 MB 29.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 29.4 MB/s eta 0:00:00\n",
      "Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.1.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, fastcore, cycler, contourpy, matplotlib, lovely-numpy, lovely-tensors\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fastcore-1.8.0 fonttools-4.56.0 kiwisolver-1.4.8 lovely-numpy-0.2.13 lovely-tensors-0.1.18 matplotlib-3.10.1 pillow-11.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7222,
     "status": "ok",
     "timestamp": 1714340664004,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "xMiwOILkRgEP",
    "outputId": "1e83443e-9aaf-4622-b4c0-33f3f2f246dd",
    "ExecuteTime": {
     "end_time": "2025-03-22T18:44:56.777884Z",
     "start_time": "2025-03-22T18:44:56.010379Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from typing import Mapping, Tuple, Sequence, List\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, LayerNorm, Module, ModuleList, Sequential\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, MultiheadAttention\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, dense_to_sparse, to_dense_batch, to_dense_adj\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
    "\n",
    "# from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(\"All imports succeeded.\")\n",
    "print(\"Python version {}\".format(sys.version))\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports succeeded.\n",
      "Python version 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]\n",
      "PyTorch version 2.6.0+cpu\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1714340664004,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "zuVTx4otRi6i",
    "outputId": "3413a2f1-30a2-413b-a451-9ad18d8e2eee",
    "ExecuteTime": {
     "end_time": "2025-03-22T18:45:05.492814Z",
     "start_time": "2025-03-22T18:45:05.486106Z"
    }
   },
   "source": [
    "# Set random seed for deterministic results\n",
    "\n",
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed(0)\n",
    "print(\"All seeds set.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seeds set.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T18:45:41.748425Z",
     "start_time": "2025-03-22T18:45:41.744662Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Cuda available: {}\".format(torch.cuda.is_available()))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6R5GR7hRdEI"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44347,
     "status": "ok",
     "timestamp": 1714340708349,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "8PVfelu6ReJe",
    "outputId": "f7970243-ac97-43f7-ff9b-4fea824e91fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/chameleon/out1_node_feature_label.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/chameleon/out1_graph_edges.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_0.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_1.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_2.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_3.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_4.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_5.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_6.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_7.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_8.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/chameleon_split_0.6_0.2_9.npz\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/squirrel/out1_node_feature_label.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/new_data/squirrel/out1_graph_edges.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_0.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_1.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_2.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_3.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_4.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_5.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_6.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_7.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_8.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/f1fc0d14b3b019c562737240d06ec83b07d16a8f/splits/squirrel_split_0.6_0.2_9.npz\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/cornell/out1_node_feature_label.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/cornell/out1_graph_edges.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_0.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_1.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_2.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_3.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_4.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_5.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_6.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_7.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_8.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/cornell_split_0.6_0.2_9.npz\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_node_feature_label.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_graph_edges.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_0.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_1.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_2.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_3.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_4.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_5.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_6.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_7.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_8.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_9.npz\n",
      "Processing...\n",
      "Done!\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_node_feature_label.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_graph_edges.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_0.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_1.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_2.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_3.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_4.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_5.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_6.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_7.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_8.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_9.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import WebKB, WikipediaNetwork\n",
    "\n",
    "DATASETS = {}\n",
    "\n",
    "# Chamelion & Squirrel\n",
    "# Cora & Citeseer\n",
    "# Cornell & Texas & Wisconsin\n",
    "\n",
    "## Mid Size Datasets\n",
    "# Citation Networks\n",
    "dataset = 'Cora'\n",
    "dataset = Planetoid('/tmp/Cora', dataset)\n",
    "data = dataset[0]\n",
    "DATASETS['Cora'] = data\n",
    "dataset = 'Citeseer'\n",
    "dataset = Planetoid('/tmp/Citeseer', dataset)\n",
    "data = dataset[0]\n",
    "DATASETS['Citeseer'] = data\n",
    "# Wikipedia Pages\n",
    "dataset = 'Chameleon'\n",
    "dataset = WikipediaNetwork(root='/tmp/Chameleon', name='Chameleon')\n",
    "data = dataset[0]\n",
    "DATASETS['Chameleon'] = data\n",
    "dataset = 'Squirrel'\n",
    "dataset = WikipediaNetwork(root='/tmp/Squirrel', name='Squirrel')\n",
    "data = dataset[0]\n",
    "DATASETS['Squirrel'] = data\n",
    "### Small Sized Datasets\n",
    "# Web Pages\n",
    "dataset = WebKB(root='/tmp/Cornell', name='Cornell')\n",
    "data = dataset[0]\n",
    "DATASETS['Cornell'] = data\n",
    "dataset = WebKB(root='/tmp/Texas', name='Texas')\n",
    "data = dataset[0]\n",
    "DATASETS['Texas'] = data\n",
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin')\n",
    "data = dataset[0]\n",
    "DATASETS['Wisconsin'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 13558,
     "status": "ok",
     "timestamp": 1714340746985,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "PqcrQ7FuVa8c"
   },
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# ### Shortest Paths ###\n",
    "# def get_shortest_path_matrix(adjacency_matrix):\n",
    "#     graph = nx.from_numpy_array(adjacency_matrix.cpu().numpy(), create_using=nx.DiGraph)\n",
    "#     shortest_path_matrix = nx.floyd_warshall_numpy(graph)\n",
    "#     shortest_path_matrix = torch.tensor(shortest_path_matrix).float()\n",
    "#     return shortest_path_matrix\n",
    "\n",
    "# SHORTEST_PATHS = {}\n",
    "# for data_key in tqdm.tqdm(DATASETS):\n",
    "#   print(data_key)\n",
    "#   data = DATASETS[data_key]\n",
    "#   dense_adj = to_dense_adj(data.edge_index, max_num_nodes = data.x.shape[0])[0]\n",
    "#   dense_shortest_path_matrix = get_shortest_path_matrix(dense_adj)\n",
    "#   SHORTEST_PATHS[data_key] = dense_shortest_path_matrix\n",
    "\n",
    "# ### Save the Shortest Paths\n",
    "# import pickle\n",
    "# with open('sp_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(SHORTEST_PATHS, f)\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65/shortest_paths/sp_dict.pkl', 'rb') as f:\n",
    "    SHORTEST_PATHS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3722,
     "status": "ok",
     "timestamp": 1714344125286,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "hzEswGTMXoOI"
   },
   "outputs": [],
   "source": [
    "for data_key in DATASETS:\n",
    "  data = DATASETS[data_key]\n",
    "  data.dense_sp_matrix = SHORTEST_PATHS[data_key]\n",
    "  data.dense_adj = to_dense_adj(data.edge_index, max_num_nodes = data.x.shape[0])[0]\n",
    "  data.dense_adj = data.dense_adj.cuda() + torch.eye(data.dense_adj.shape[0]).cuda()\n",
    "  data.dense_adj[data.dense_adj == 2] = 1\n",
    "  data = T.AddLaplacianEigenvectorPE(k = 16, attr_name = 'pos_enc')(data)\n",
    "  DATASETS[data_key] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1714340709202,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "vsqv_LTEU-2H"
   },
   "outputs": [],
   "source": [
    "### Masks ###\n",
    "\n",
    "def generate_masks(num_nodes=None,num_runs=None,train_ratio=None, val_ratio=None):\n",
    "    masks = { 'train_mask': np.zeros((num_nodes, num_runs), dtype=int),\n",
    "              'val_mask': np.zeros((num_nodes, num_runs), dtype=int),\n",
    "              'test_mask': np.zeros((num_nodes, num_runs), dtype=int)}\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        indices = np.arange(num_nodes)\n",
    "        np.random.shuffle(indices)\n",
    "        train_end = int(train_ratio * num_nodes)\n",
    "        val_end = train_end + int(val_ratio * num_nodes)\n",
    "        masks['train_mask'][indices[:train_end], run] = 1\n",
    "        masks['val_mask'][indices[train_end:val_end], run] = 1\n",
    "        masks['test_mask'][indices[val_end:], run] = 1\n",
    "\n",
    "    tensor_masks = {'train_mask': torch.tensor(masks['train_mask']),\n",
    "                    'val_mask':torch.tensor(masks['val_mask']),\n",
    "                    'test_mask':torch.tensor(masks['test_mask'])}\n",
    "    return tensor_masks\n",
    "\n",
    "for data_key in DATASETS:\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    masks = generate_masks(num_nodes=data.x.shape[0], num_runs=10, train_ratio=0.4, val_ratio=0.3)\n",
    "    data.train_mask = masks['train_mask'].bool()\n",
    "    data.val_mask = masks['val_mask'].bool()\n",
    "    data.test_mask = masks['test_mask'].bool()\n",
    "\n",
    "    if len(data.train_mask.shape)==1:\n",
    "      print('Add 10 Masks')\n",
    "    else:\n",
    "      print('We have 10 Masks')\n",
    "      print('Train Ratio:',(data.train_mask[:,0].sum() / len(data.train_mask[:,0])).item())\n",
    "      print('Val Ratio:',(data.val_mask[:,0].sum() / len(data.val_mask[:,0])).item())\n",
    "      print('Test Ratio:',(data.test_mask[:,0].sum() / len(data.test_mask[:,0])).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPGL9tFORJCQ"
   },
   "source": [
    "## Table 1: Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1714340709202,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "O34_wDE-RLre"
   },
   "outputs": [],
   "source": [
    "### Table 1 ###\n",
    "### Dataset Statistics ###\n",
    "import dgl\n",
    "Homophily_Levels = {}\n",
    "\n",
    "for data_key in DATASETS:\n",
    "  data = DATASETS[data_key]\n",
    "  edge_index_tensor = torch.tensor(data.edge_index.cpu().numpy(), dtype=torch.long)\n",
    "  g = dgl.graph((edge_index_tensor[0], edge_index_tensor[1]), num_nodes=data.x.shape[0])\n",
    "  g.ndata['y'] = torch.tensor(data.y.cpu().numpy(), dtype=torch.long)\n",
    "  Homophily_Levels[data_key] = {'Node Homophily':dgl.node_homophily(g, g.ndata['y'])*100,\n",
    "                                'Edge Homophily':dgl.edge_homophily(g, g.ndata['y'])*100,\n",
    "                                'Adjusted Homophily':dgl.adjusted_homophily(g, g.ndata['y'])*100,\n",
    "                                'Number of Nodes': int(g.num_nodes()),\n",
    "                                'Number of Edges': int(g.num_edges())\n",
    "                                }\n",
    "df = pd.DataFrame(Homophily_Levels).round(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JV4ZtidSENR"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKL9b7tCSDDd"
   },
   "outputs": [],
   "source": [
    "# PyG example code: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_cora.py\n",
    "\n",
    "class GNNModel(Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int = data.x.shape[-1],\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            out_dim: int = len(data.y.unique()),\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_in = Linear(in_dim, hidden_dim)\n",
    "        self.lin_out = Linear(hidden_dim, out_dim)\n",
    "        self.layers = ModuleList()\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                GCNConv(hidden_dim, hidden_dim)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.lin_in(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # conv -> activation ->  dropout -> residual\n",
    "            x_in = x\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = x_in + x\n",
    "\n",
    "        x = self.lin_out(x)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "class SparseGraphTransformerModel(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int = data.x.shape[-1],\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            out_dim: int = len(data.y.unique()),\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_in = Linear(in_dim, hidden_dim)\n",
    "        self.lin_out = Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                MultiheadAttention(\n",
    "                    embed_dim = hidden_dim,\n",
    "                    num_heads = num_heads,\n",
    "                    dropout = dropout\n",
    "                )\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, dense_adj):\n",
    "\n",
    "        x = self.lin_in(x)\n",
    "\n",
    "        self.attn_weights_list = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_in = x\n",
    "            x, attn_weights = layer(\n",
    "                x, x, x,\n",
    "                attn_mask = ~dense_adj.bool(),\n",
    "                average_attn_weights = False\n",
    "            )\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = x_in + x\n",
    "\n",
    "            self.attn_weights_list.append(attn_weights)\n",
    "\n",
    "        x = self.lin_out(x)\n",
    "\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "class DenseGraphTransformerModel(Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int = data.x.shape[-1],\n",
    "            pos_enc_dim: int = 16,\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            out_dim: int = len(data.y.unique()),\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_in = Linear(in_dim, hidden_dim)\n",
    "        self.lin_pos_enc = Linear(pos_enc_dim, hidden_dim)\n",
    "        self.lin_out = Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                MultiheadAttention(\n",
    "                    embed_dim = hidden_dim,\n",
    "                    num_heads = num_heads,\n",
    "                    dropout = dropout\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "        self.attn_bias_scale = torch.nn.Parameter(torch.tensor([10.0]))  # controls how much we initially bias our model to nearby nodes\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, pos_enc, dense_sp_matrix):\n",
    "\n",
    "        # x = self.lin_in(x) + self.lin_pos_enc(pos_enc)\n",
    "        x = self.lin_in(x)  # no node positional encoding\n",
    "\n",
    "        # attention bias\n",
    "        # [i, j] -> inverse of shortest path distance b/w node i and j\n",
    "        # diagonals -> self connection, set to 0\n",
    "        # disconnected nodes -> -1\n",
    "        attn_bias = self.attn_bias_scale * torch.nan_to_num(\n",
    "            (1 / (torch.nan_to_num(dense_sp_matrix, nan=-1, posinf=-1, neginf=-1))),\n",
    "            nan=0, posinf=0, neginf=0)\n",
    "        #attn_bias = torch.ones_like(attn_bias)\n",
    "\n",
    "        # TransformerEncoder\n",
    "        # x = self.encoder(x, mask = attn_bias)\n",
    "\n",
    "        self.attn_weights_list = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # MHSA layer\n",
    "            # float mask adds learnable additive attention bias\n",
    "            x_in = x\n",
    "            x, attn_weights = layer(\n",
    "                x, x, x,\n",
    "                attn_mask = attn_bias,\n",
    "                average_attn_weights = False\n",
    "            )\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = x_in + x\n",
    "\n",
    "            self.attn_weights_list.append(attn_weights)\n",
    "\n",
    "        x = self.lin_out(x)\n",
    "\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "class DenseGraphTransformerModel_V2(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int = data.x.shape[-1],\n",
    "            pos_enc_dim: int = 16,\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            out_dim: int = len(data.y.unique()),\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_in = Linear(in_dim, hidden_dim)\n",
    "        self.lin_pos_enc = Linear(pos_enc_dim, hidden_dim)\n",
    "        self.lin_out = Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                MultiheadAttention(\n",
    "                    embed_dim = hidden_dim,\n",
    "                    num_heads = num_heads,\n",
    "                    dropout = dropout\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.attn_bias_scale = torch.nn.Parameter(torch.tensor([10.0]))  # controls how much we initially bias our model to nearby nodes\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, pos_enc, dense_sp_matrix):\n",
    "\n",
    "        x = self.lin_in(x) + self.lin_pos_enc(pos_enc)\n",
    "        # x = self.lin_in(x)  # no node positional encoding\n",
    "\n",
    "        # attention bias\n",
    "        # [i, j] -> inverse of shortest path distance b/w node i and j\n",
    "        # diagonals -> self connection, set to 0\n",
    "        # disconnected nodes -> -1\n",
    "        # attn_bias = self.attn_bias_scale * torch.nan_to_num(\n",
    "        #     (1 / (torch.nan_to_num(dense_sp_matrix, nan=-1, posinf=-1, neginf=-1))),\n",
    "        #     nan=0, posinf=0, neginf=0\n",
    "        # )\n",
    "        #attn_bias = torch.ones_like(attn_bias)\n",
    "\n",
    "        # TransformerEncoder\n",
    "        # x = self.encoder(x, mask = attn_bias)\n",
    "\n",
    "        self.attn_weights_list = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # # TransformerEncoderLayer\n",
    "            # # float mask adds learnable additive attention bias\n",
    "            # x = layer(x, src_mask = attn_bias)\n",
    "\n",
    "            # MHSA layer\n",
    "            # float mask adds learnable additive attention bias\n",
    "            x_in = x\n",
    "            x, attn_weights = layer(\n",
    "                x, x, x,\n",
    "                # attn_mask = attn_bias,\n",
    "                average_attn_weights = False\n",
    "            )\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = x_in + x\n",
    "\n",
    "            self.attn_weights_list.append(attn_weights)\n",
    "\n",
    "        x = self.lin_out(x)\n",
    "\n",
    "        return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z39ODu9oT2f9"
   },
   "source": [
    "# Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgXWrDZ5V_al"
   },
   "outputs": [],
   "source": [
    "def Train_GCN(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data):\n",
    "\n",
    "    IN_DIM = data.x.shape[-1]\n",
    "    OUT_DIM = len(data.y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = GNNModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred, accs = model(data.x, data.edge_index).argmax(dim=-1), []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(1, 100):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
    "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
    "        #       f'Final Test: {test_acc:.4f}')\n",
    "        times.append(time.time() - start)\n",
    "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, None\n",
    "\n",
    "def Train_SparseGraphTransformerModel(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data):\n",
    "\n",
    "    IN_DIM = data.x.shape[-1]\n",
    "    OUT_DIM = len(data.y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = SparseGraphTransformerModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.dense_adj)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred, accs = model(data.x, data.dense_adj).argmax(dim=-1), []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(1, 100):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
    "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
    "        #       f'Final Test: {test_acc:.4f}')\n",
    "        times.append(time.time() - start)\n",
    "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
    "\n",
    "def Train_DenseGraphTransformerModel(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data):\n",
    "\n",
    "    IN_DIM = data.x.shape[-1]\n",
    "    OUT_DIM = len(data.y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = DenseGraphTransformerModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.pos_enc)\n",
    "        out = model(data.x, data.pos_enc, data.dense_sp_matrix)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred, accs = model(data.x, data.pos_enc, data.dense_sp_matrix).argmax(dim=-1), []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(1, 100):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
    "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
    "        #       f'Final Test: {test_acc:.4f}')\n",
    "        times.append(time.time() - start)\n",
    "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
    "\n",
    "    # Notes\n",
    "    # - Dense Transformer needs to be trained for a bit longer to reach low loss value\n",
    "    # - Node positional encodings are not particularly useful\n",
    "    # - Edge distance encodings are very useful\n",
    "    # - Since Cora is highly homophilic, it is important to bias the attention towards nearby nodes\n",
    "\n",
    "def Train_DenseGraphTransformerModel_V2(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data):\n",
    "\n",
    "    IN_DIM = data.x.shape[-1]\n",
    "    OUT_DIM = len(data.y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = DenseGraphTransformerModel_V2(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.pos_enc, data.dense_sp_matrix)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred, accs = model(data.x, data.pos_enc, data.dense_sp_matrix).argmax(dim=-1), []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(1, 100):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
    "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
    "        #       f'Final Test: {test_acc:.4f}')\n",
    "        times.append(time.time() - start)\n",
    "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
    "\n",
    "    # Notes\n",
    "    # - Dense Transformer needs to be trained for a bit longer to reach low loss value\n",
    "    # - Node positional encodings are not particularly useful\n",
    "    # - Edge distance encodings are very useful\n",
    "    # - Since Cora is highly homophilic, it is important to bias the attention towards nearby nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veDrDxJIaO7f"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3wGJPl3YJcd"
   },
   "source": [
    "## Training: 1 Layer, 1 Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229201,
     "status": "ok",
     "timestamp": 1710738973707,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "y6GoLurKW57q",
    "outputId": "5a2e6a7c-8104-4d38-cdff-fb422102fd9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "NUM_LAYERS = 1\n",
    "NUM_HEADS = 1\n",
    "NUM_RUNS = 10\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxj1ye0Y1ZwC"
   },
   "source": [
    "## Training: 1 Layer, 2 Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350257,
     "status": "ok",
     "timestamp": 1710739323962,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "1igyz0Pr1dRN",
    "outputId": "007dcfb4-f029-465a-81fe-05b0ac2fb881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:32<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:52<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "NUM_LAYERS = 1\n",
    "NUM_HEADS = 2\n",
    "NUM_RUNS = 10\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWeKuQTt1k_M"
   },
   "source": [
    "## Training: 2 Layers, 1 Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393297,
     "status": "ok",
     "timestamp": 1710739717256,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "zcAfw7My1oij",
    "outputId": "9a14a337-b5e8-458a-8573-4ce8a7a50711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:56<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "### Train Cora ###\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 1\n",
    "NUM_RUNS = 10\n",
    "# data_key = 'Wisconsin'\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel'])\n",
    "        attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel'])\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2'])\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hMUb2yK1pEB"
   },
   "source": [
    "## Training: 2 Layers, 2 Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 643061,
     "status": "ok",
     "timestamp": 1710740360315,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "YYmZVaET1sKD",
    "outputId": "e7aec9f4-9e13-4f97-f939-e114ca8fc868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:58<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:35<00:00,  9.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import tqdm\n",
    "### Train Cora ###\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 2\n",
    "NUM_RUNS = 10\n",
    "# data_key = 'Wisconsin'\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        gc.collect()\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXuPgGbGa2Nd"
   },
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "670dtom5sl10"
   },
   "source": [
    "## Table 2: Accuracy Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNkbWu7zH06U"
   },
   "outputs": [],
   "source": [
    "### Table 2 ###\n",
    "### Accuracy Statistics ###\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "all_stats_df = {}\n",
    "for data_key in all_stats:\n",
    "  run_stats = all_stats[data_key]\n",
    "  table1 = pd.concat({key : pd.DataFrame(run_stats[key]['accuracy']) for key in run_stats}, axis=0)\n",
    "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
    "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
    "  # table1 = pd.concat({'Train': table1_train, 'Test': table1_test}, axis=1)\n",
    "  table1 = table1_test\n",
    "  all_stats_df[data_key] = table1\n",
    "pd.concat(all_stats_df, axis=1).round(2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7QF060g8m/oZks22EC8jM",
   "collapsed_sections": [
    "Fxj1ye0Y1ZwC",
    "sWeKuQTt1k_M",
    "2hMUb2yK1pEB",
    "ZXuPgGbGa2Nd",
    "670dtom5sl10"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1nYy2OQQ4os8qAJRaYQ2kwsbNjzw3zFyx",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
