{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/batu-el/understanding-inductive-biases-of-gnns/blob/main/notebooks/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tVe55J-aw7aC",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:07:14.166677Z",
     "start_time": "2025-03-24T04:07:14.164060Z"
    }
   },
   "source": [
    "# Combining Attention values across heads - Avg\n",
    "# Combining Attention values across layers - Matrix Multiply"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRR5bUiLRZ5a"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95820,
     "status": "ok",
     "timestamp": 1714340656785,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "JLx8ARPERaaB",
    "outputId": "39a34a44-a10f-4423-81a8-ca4638185152",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:07:20.810500Z",
     "start_time": "2025-03-24T04:07:14.220885Z"
    }
   },
   "source": [
    "!pip install dgl torch_geometric torch openhgnn\n",
    "\n",
    "# Install required python libraries\n",
    "import os\n",
    "\n",
    "# Install PyTorch Geometric and other libraries\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    print(\"Installing PyTorch Geometric\")\n",
    "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "    !pip install -q torch-geometric\n",
    "    print(\"Installing other libraries\")\n",
    "    !pip install networkx\n",
    "    !pip install lovely-tensors"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgl in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torch_geometric in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: torch in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: openhgnn in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (1.15.2)\n",
      "Requirement already satisfied: networkx>=2.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (3.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (4.67.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (7.0.0)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (0.11.0)\n",
      "Requirement already satisfied: pandas in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from dgl) (2.2.3)\n",
      "Requirement already satisfied: aiohttp in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch_geometric) (3.11.14)\n",
      "Requirement already satisfied: fsspec in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch_geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: pyparsing in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch_geometric) (3.2.1)\n",
      "Requirement already satisfied: filelock in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: ogb>=1.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from openhgnn) (1.3.6)\n",
      "Requirement already satisfied: optuna in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from openhgnn) (4.2.1)\n",
      "Requirement already satisfied: colorama in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from openhgnn) (0.4.6)\n",
      "Requirement already satisfied: TensorBoard>=2.0.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from openhgnn) (2.19.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ogb>=1.1.0->openhgnn) (1.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ogb>=1.1.0->openhgnn) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ogb>=1.1.0->openhgnn) (2.3.0)\n",
      "Requirement already satisfied: outdated>=0.2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ogb>=1.1.0->openhgnn) (0.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from pandas->dgl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from pandas->dgl) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from pandas->dgl) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (3.7)\n",
      "Requirement already satisfied: packaging in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (6.30.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (75.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from TensorBoard>=2.0.0->openhgnn) (3.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from optuna->openhgnn) (1.15.1)\n",
      "Requirement already satisfied: colorlog in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from optuna->openhgnn) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from optuna->openhgnn) (2.0.39)\n",
      "Requirement already satisfied: PyYAML in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from optuna->openhgnn) (6.0.2)\n",
      "Requirement already satisfied: Mako in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna->openhgnn) (1.3.9)\n",
      "Requirement already satisfied: littleutils in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from outdated>=0.2.0->ogb>=1.1.0->openhgnn) (0.2.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from scikit-learn>=0.20.0->ogb>=1.1.0->openhgnn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from scikit-learn>=0.20.0->ogb>=1.1.0->openhgnn) (3.6.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->openhgnn) (3.1.1)\n",
      "Installing PyTorch Geometric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing other libraries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (3.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lovely-tensors in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (0.1.18)\n",
      "Requirement already satisfied: torch in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-tensors) (2.6.0)\n",
      "Requirement already satisfied: lovely-numpy>=0.2.13 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-tensors) (0.2.13)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-numpy>=0.2.13->lovely-tensors) (2.2.4)\n",
      "Requirement already satisfied: fastcore in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-numpy>=0.2.13->lovely-tensors) (1.8.0)\n",
      "Requirement already satisfied: ipython in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-numpy>=0.2.13->lovely-tensors) (9.0.2)\n",
      "Requirement already satisfied: matplotlib in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from lovely-numpy>=0.2.13->lovely-tensors) (3.10.1)\n",
      "Requirement already satisfied: filelock in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from torch->lovely-tensors) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from sympy==1.13.1->torch->lovely-tensors) (1.3.0)\n",
      "Requirement already satisfied: packaging in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from fastcore->lovely-numpy>=0.2.13->lovely-tensors) (24.2)\n",
      "Requirement already satisfied: colorama in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from ipython->lovely-numpy>=0.2.13->lovely-tensors) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from jinja2->torch->lovely-tensors) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (2.9.0.post0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from jedi>=0.16->ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lovely-numpy>=0.2.13->lovely-tensors) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from stack_data->ipython->lovely-numpy>=0.2.13->lovely-tensors) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from stack_data->ipython->lovely-numpy>=0.2.13->lovely-tensors) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\pycharmprojects\\graph_attention_interpretability\\.venv\\lib\\site-packages (from stack_data->ipython->lovely-numpy>=0.2.13->lovely-tensors) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7222,
     "status": "ok",
     "timestamp": 1714340664004,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "xMiwOILkRgEP",
    "outputId": "1e83443e-9aaf-4622-b4c0-33f3f2f246dd",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:05.223449Z",
     "start_time": "2025-03-24T04:08:02.106510Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from typing import Mapping, Tuple, Sequence, List\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, LayerNorm, Module, ModuleList, Sequential\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, MultiheadAttention\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import remove_self_loops, dense_to_sparse, to_dense_batch, to_dense_adj\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
    "\n",
    "# from openhgnn.dataset import d\n",
    "\n",
    "# from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(\"All imports succeeded.\")\n",
    "print(\"Python version {}\".format(sys.version))\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "D:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports succeeded.\n",
      "Python version 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]\n",
      "PyTorch version 2.6.0+cpu\n",
      "PyG version 2.6.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1714340664004,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "zuVTx4otRi6i",
    "outputId": "3413a2f1-30a2-413b-a451-9ad18d8e2eee",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:07.436802Z",
     "start_time": "2025-03-24T04:08:07.429354Z"
    }
   },
   "source": [
    "# Set random seed for deterministic results\n",
    "\n",
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed(0)\n",
    "print(\"All seeds set.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All seeds set.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:08.151250Z",
     "start_time": "2025-03-24T04:08:08.148208Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Cuda available: {}\".format(torch.cuda.is_available()))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6R5GR7hRdEI"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44347,
     "status": "ok",
     "timestamp": 1714340708349,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "8PVfelu6ReJe",
    "outputId": "f7970243-ac97-43f7-ff9b-4fea824e91fa",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:10.807465Z",
     "start_time": "2025-03-24T04:08:10.740903Z"
    }
   },
   "source": [
    "from torch_geometric.datasets import IMDB\n",
    "\n",
    "DATASETS = {}\n",
    "\n",
    "# (same as the imdb4MAGNN dataset from OpenHGNN)\n",
    "dataset = IMDB(root='/tmp/IMDB')\n",
    "data = dataset[0]\n",
    "DATASETS['IMDB'] = data\n",
    "DATASETS"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMDB': HeteroData(\n",
       "   movie={\n",
       "     x=[4278, 3066],\n",
       "     y=[4278],\n",
       "     train_mask=[4278],\n",
       "     val_mask=[4278],\n",
       "     test_mask=[4278],\n",
       "   },\n",
       "   director={ x=[2081, 3066] },\n",
       "   actor={ x=[5257, 3066] },\n",
       "   (movie, to, director)={ edge_index=[2, 4278] },\n",
       "   (movie, to, actor)={ edge_index=[2, 12828] },\n",
       "   (director, to, movie)={ edge_index=[2, 4278] },\n",
       "   (actor, to, movie)={ edge_index=[2, 12828] }\n",
       " )}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:11.886045Z",
     "start_time": "2025-03-24T04:08:11.881928Z"
    }
   },
   "cell_type": "code",
   "source": "DATASETS[\"IMDB\"].edge_types",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 'to', 'director'),\n",
       " ('movie', 'to', 'actor'),\n",
       " ('director', 'to', 'movie'),\n",
       " ('actor', 'to', 'movie')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:12.178928Z",
     "start_time": "2025-03-24T04:08:12.174778Z"
    }
   },
   "cell_type": "code",
   "source": "DATASETS[\"IMDB\"][('movie', 'to', 'director')].edge_index[0].max()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor i64 4277"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:12.516179Z",
     "start_time": "2025-03-24T04:08:12.511881Z"
    }
   },
   "cell_type": "code",
   "source": "DATASETS[\"IMDB\"][('movie', 'to', 'director')].edge_index[1].max()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor i64 2080"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:12.800901Z",
     "start_time": "2025-03-24T04:08:12.797759Z"
    }
   },
   "cell_type": "code",
   "source": "DATASETS[\"IMDB\"].dense_adj = {}",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 3722,
     "status": "ok",
     "timestamp": 1714344125286,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": -60
    },
    "id": "hzEswGTMXoOI",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:13.215017Z",
     "start_time": "2025-03-24T04:08:13.078692Z"
    }
   },
   "source": [
    "for data_key in DATASETS:\n",
    "    data = DATASETS[data_key]\n",
    "    # data.dense_sp_matrix = SHORTEST_PATHS[data_key]\n",
    "    # data.dense_adj = to_dense_adj(data.edge_index, max_num_nodes = data.x.shape[0])[0]\n",
    "\n",
    "    data.dense_adj = {}\n",
    "    for e_type in data.edge_types:\n",
    "\n",
    "        src_type, _, dst_type = e_type \n",
    "        edge_index = data[e_type].edge_index\n",
    "\n",
    "        num_src = data[src_type].num_nodes\n",
    "        num_dst = data[dst_type].num_nodes\n",
    "        \n",
    "        src = edge_index[0]\n",
    "        dst = edge_index[1] + num_src\n",
    "\n",
    "        combined_edge_index = torch.stack([src, dst], dim=0)\n",
    "\n",
    "        dense_adj = to_dense_adj(\n",
    "            combined_edge_index,\n",
    "            max_num_nodes=num_src + num_dst\n",
    "        )[0]\n",
    "        \n",
    "        dense_adj.fill_diagonal_(1)\n",
    "        \n",
    "        # below approach createst a rectangular matrix where each dim corresponds to a row type. However, rectangular are required...\n",
    "        # # instead of creating a square matrix, we will do rectangular of shape (node_A x node_B) since we only care about edges between these types\n",
    "        # dense_adj = torch.zeros((num_src, num_dst), dtype=torch.long)\n",
    "        # \n",
    "        # for src, dst in data[e_type].edge_index.T:\n",
    "        #     dense_adj[src, dst] = 1\n",
    "            \n",
    "        data.dense_adj[e_type] = dense_adj\n",
    "\n",
    "    DATASETS[data_key] = data"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPGL9tFORJCQ"
   },
   "source": [
    "## Table 1: Dataset Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JV4ZtidSENR"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:09:47.689806Z",
     "start_time": "2025-03-24T04:09:47.684218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import HeteroConv\n",
    "\n",
    "class HeteroGNNModel(Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            metadata, \n",
    "            gnn_layer,\n",
    "            out_node_type,\n",
    "            in_feat_dims: dict[str, int],\n",
    "            hidden_dim=128,\n",
    "            out_dim=None,\n",
    "            num_heads=1,\n",
    "            num_layers=1,\n",
    "            dropout=.8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Heterogeneous GNN model wrapper for applying layers to each edge type. Specifically used for node classification. \n",
    "        \n",
    "        :param metadata: from HeteroData object. Contains edge/node types\n",
    "        :param gnn_layer: type of attention layer to use for each edge type\n",
    "        :param node_type: type of node to perform classification on\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_node_type = out_node_type \n",
    "        \n",
    "        # use for converting all node features to same representation size (i.e., hidden_size)\n",
    "        self.lin_in = torch.nn.ModuleDict({\n",
    "            node_type: torch.nn.Linear(in_feat_dims[node_type], hidden_dim)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.convs = HeteroConv({\n",
    "            edge_type: gnn_layer(\n",
    "                in_dim=hidden_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                num_heads=num_heads,\n",
    "                num_layers=num_layers,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            for edge_type in metadata[1]\n",
    "        }, aggr='sum'   # how embeddings for the same node type are combined across edge types\n",
    "        )\n",
    " \n",
    "        # self.lin_out = torch.nn.Sequential(\n",
    "        #     Linear(hidden_dim, hidden_dim // 2),\n",
    "        #     torch.nn.ReLU(),\n",
    "        #     Linear(hidden_dim // 2, out_dim),\n",
    "        # )\n",
    "        \n",
    "        self.lin_out = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        # self.attn_weights_dict = {}\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # same representation size for each node type input feature (i.e., hidden_size)\n",
    "        x_dict = {\n",
    "            node_type: self.lin_in[node_type](x)\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "\n",
    "        # run attention model on each edge type to produce final node embeddings for classification\n",
    "        # returns a dict with embeddings for each node, so we need to retrieve the type used for classification\n",
    "        x = self.convs(x_dict, edge_index_dict)[self.out_node_type]\n",
    "        \n",
    "        # classify nodes\n",
    "        out = self.lin_out(x)\n",
    "        return out.log_softmax(dim=-1)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AKL9b7tCSDDd",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:08:22.333483Z",
     "start_time": "2025-03-24T04:08:22.322596Z"
    }
   },
   "source": [
    "# PyG example code: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_cora.py\n",
    "\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "# Replace with graph conv for bipartite message passing in heterogeneous graphs\n",
    "class GNNModel(Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                GraphConv(hidden_dim, hidden_dim, aggr=\"mean\")\n",
    "            )\n",
    "            \n",
    "        self.lin_src = torch.nn.Linear(in_dim, hidden_dim)\n",
    "        self.lin_dst = torch.nn.Linear(in_dim, hidden_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        if isinstance(x, tuple):\n",
    "            x_src, x_dst = x\n",
    "            x_src = self.lin_src(x_src)\n",
    "            x_dst = self.lin_dst(x_dst)\n",
    "        else:\n",
    "            x_src = x_dst = self.lin_src(x)\n",
    "\n",
    "        for conv in self.layers:\n",
    "            x_out = conv(x, edge_index)  # x is a tuple in bipartite\n",
    "            x_out = F.relu(x_out)\n",
    "            x_out = F.dropout(x_out, p=self.dropout, training=self.training)\n",
    "            x_dst = x_dst + x_out  # residual connection\n",
    "            x = (x_src, x_dst)\n",
    "            \n",
    "        return x_dst\n",
    "\n",
    "\n",
    "class SparseGraphTransformerModel(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin_src = torch.nn.Linear(in_dim, hidden_dim)\n",
    "        self.lin_dst = torch.nn.Linear(in_dim, hidden_dim)\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                MultiheadAttention(\n",
    "                    embed_dim = hidden_dim,\n",
    "                    num_heads = num_heads,\n",
    "                    dropout = dropout,\n",
    "                    batch_first = False\n",
    "                )\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.attn_weights_list = []\n",
    "\n",
    "    def forward(self, x, dense_adj):\n",
    "\n",
    "        if isinstance(x, tuple):\n",
    "            x_src, x_dst = x\n",
    "            x_src = self.lin_src(x_src)\n",
    "            x_dst = self.lin_dst(x_dst)\n",
    "        else:\n",
    "            x_src = x_dst = self.lin_src(x)\n",
    "    \n",
    "        # concatenate for use in multi-head attention\n",
    "        x_cat = torch.cat([x_src, x_dst], dim=0)   # [n_src + n_dst, hidden_dim]\n",
    "        \n",
    "        x_cat = x_cat.unsqueeze(1)  # [n_src + n_dst, 1, hidden_dim]\n",
    "        \n",
    "        # 4) Prepare the attention mask.\n",
    "        #    MHA expects a bool mask of shape [T, T], where True = \"NO ATTEND\".\n",
    "        #    So we invert dense_adj if we want 1=connected, 0=not connected.\n",
    "        attn_mask = ~(dense_adj.bool())  # True where there's NO edge => block attention\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_in = x_cat\n",
    "            x, attn_weights = layer(\n",
    "                x_cat, x_cat, x_cat,\n",
    "                attn_mask = attn_mask,\n",
    "                need_weights = True,\n",
    "                average_attn_weights = False\n",
    "            )\n",
    "            \n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x_cat = x_in + x\n",
    "\n",
    "            # self.attn_weights_list.append(attn_weights)\n",
    "\n",
    "        # [n_src + n_dst, hidden_dim]\n",
    "        x_cat = x_cat.squeeze(1)\n",
    "        \n",
    "        out_dst = x_cat[x_src.size(0):]\n",
    "        \n",
    "\n",
    "        return out_dst\n",
    "\n",
    "# Skip for now since uses shortest path\n",
    "class DenseGraphTransformerModel(Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            pos_enc_dim: int = 16,\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_in = Linear(in_dim, hidden_dim)\n",
    "        self.lin_pos_enc = Linear(pos_enc_dim, hidden_dim)\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                MultiheadAttention(\n",
    "                    embed_dim = hidden_dim,\n",
    "                    num_heads = num_heads,\n",
    "                    dropout = dropout\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "        self.attn_bias_scale = torch.nn.Parameter(torch.tensor([10.0]))  # controls how much we initially bias our model to nearby nodes\n",
    "        self.dropout = dropout\n",
    "        self.attn_weights_list = []\n",
    "\n",
    "    def forward(self, x, pos_enc, dense_sp_matrix):\n",
    "\n",
    "        # x = self.lin_in(x) + self.lin_pos_enc(pos_enc)\n",
    "        x = self.lin_in(x)  # no node positional encoding\n",
    "\n",
    "        # attention bias\n",
    "        # [i, j] -> inverse of shortest path distance b/w node i and j\n",
    "        # diagonals -> self connection, set to 0\n",
    "        # disconnected nodes -> -1\n",
    "        attn_bias = self.attn_bias_scale * torch.nan_to_num(\n",
    "            (1 / (torch.nan_to_num(dense_sp_matrix, nan=-1, posinf=-1, neginf=-1))),\n",
    "            nan=0, posinf=0, neginf=0)\n",
    "        #attn_bias = torch.ones_like(attn_bias)\n",
    "\n",
    "        # TransformerEncoder\n",
    "        # x = self.encoder(x, mask = attn_bias)\n",
    "\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # MHSA layer\n",
    "            # float mask adds learnable additive attention bias\n",
    "            x_in = x\n",
    "            x, attn_weights = layer(\n",
    "                x, x, x,\n",
    "                attn_mask = attn_bias,\n",
    "                average_attn_weights = False\n",
    "            )\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = x_in + x\n",
    "\n",
    "            self.attn_weights_list.append(attn_weights)\n",
    "\n",
    "        # x = self.lin_out(x)\n",
    "        # \n",
    "        # return x.log_softmax(dim=-1)\n",
    "        return x\n",
    "\n",
    "# doesn't use shortest path bias\n",
    "class DenseGraphTransformerModel_V2(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            pos_enc_dim: int = 16,\n",
    "            hidden_dim: int = 128,\n",
    "            num_heads: int = 1,\n",
    "            num_layers: int = 1,\n",
    "            dropout: float = 0.5,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_in = Linear(in_dim, hidden_dim)\n",
    "        self.lin_pos_enc = Linear(pos_enc_dim, hidden_dim)\n",
    "\n",
    "        self.layers = ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.layers.append(\n",
    "                MultiheadAttention(\n",
    "                    embed_dim = hidden_dim,\n",
    "                    num_heads = num_heads,\n",
    "                    dropout = dropout\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.attn_bias_scale = torch.nn.Parameter(torch.tensor([10.0]))  # controls how much we initially bias our model to nearby nodes\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, pos_enc, dense_sp_matrix):\n",
    "\n",
    "        # x = self.lin_in(x) + self.lin_pos_enc(pos_enc)\n",
    "        x = self.lin_in(x)  # no node positional encoding\n",
    "\n",
    "        # attention bias\n",
    "        # [i, j] -> inverse of shortest path distance b/w node i and j\n",
    "        # diagonals -> self connection, set to 0\n",
    "        # disconnected nodes -> -1\n",
    "        # attn_bias = self.attn_bias_scale * torch.nan_to_num(\n",
    "        #     (1 / (torch.nan_to_num(dense_sp_matrix, nan=-1, posinf=-1, neginf=-1))),\n",
    "        #     nan=0, posinf=0, neginf=0\n",
    "        # )\n",
    "        #attn_bias = torch.ones_like(attn_bias)\n",
    "\n",
    "        # TransformerEncoder\n",
    "        # x = self.encoder(x, mask = attn_bias)\n",
    "\n",
    "        self.attn_weights_list = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # # TransformerEncoderLayer\n",
    "            # # float mask adds learnable additive attention bias\n",
    "            # x = layer(x, src_mask = attn_bias)\n",
    "\n",
    "            # MHSA layer\n",
    "            # float mask adds learnable additive attention bias\n",
    "            x_in = x\n",
    "            x, attn_weights = layer(\n",
    "                x, x, x,\n",
    "                # attn_mask = attn_bias,\n",
    "                average_attn_weights = False\n",
    "            )\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = x_in + x\n",
    "\n",
    "            self.attn_weights_list.append(attn_weights)\n",
    "\n",
    "        # x = self.lin_out(x)\n",
    "        # \n",
    "        # return x.log_softmax(dim=-1)\n",
    "        return x\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T04:36:18.742081Z",
     "start_time": "2025-03-24T04:36:18.737645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# class GNNModel(Module):\n",
    "# \n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             in_dim: int = 3066,\n",
    "#             hidden_dim: int = 128,\n",
    "#             num_heads: int = 1,\n",
    "#             num_layers: int = 1,\n",
    "#             out_dim: int = 3,\n",
    "#             dropout: float = 0.8,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "# \n",
    "#         self.lin_in = Linear(in_dim, hidden_dim)\n",
    "#         self.lin_out = Linear(hidden_dim, out_dim)\n",
    "#         self.layers = ModuleList()\n",
    "# \n",
    "#         for layer in range(num_layers):\n",
    "#             self.layers.append(\n",
    "#                 GraphConv(hidden_dim, hidden_dim)\n",
    "#             )\n",
    "#         self.dropout = torch.nn.Dropout(dropout)\n",
    "# \n",
    "#     def forward(self, x, edge_index):\n",
    "# \n",
    "#         x = self.lin_in(x)\n",
    "# \n",
    "#         for layer in self.layers:\n",
    "#             # conv -> activation ->  dropout -> residual\n",
    "#             x_in = x\n",
    "#             x = layer(x, edge_index)\n",
    "#             x = F.relu(x)\n",
    "#             x = self.dropout(x)\n",
    "#             x = x_in + x\n",
    "# \n",
    "#         return x"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z39ODu9oT2f9"
   },
   "source": "# Trainers"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bgXWrDZ5V_al",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:36:21.519819Z",
     "start_time": "2025-03-24T04:36:21.502013Z"
    }
   },
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "def Train_GCN(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data,\n",
    "              out_node_type):\n",
    "\n",
    "    OUT_DIM = len(data[out_node_type].y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = HeteroGNNModel(\n",
    "        data.metadata(), \n",
    "        GNNModel, \n",
    "        in_feat_dims={node_type: data[node_type].x.shape[1] for node_type in data.metadata()[0]},\n",
    "        out_node_type=out_node_type,\n",
    "        hidden_dim=128,\n",
    "        out_dim=OUT_DIM,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        num_heads=NUM_HEADS,\n",
    "    ).to(device)\n",
    "\n",
    "    # uncomment for to_hetero approach. Similar results..\n",
    "    # model = GNNModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS ,out_dim=OUT_DIM).to(device)\n",
    "    # model = torch_geometric.nn.to_hetero(model, data.metadata(), aggr='sum')\n",
    "    \n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    train_mask = data[out_node_type].train_mask\n",
    "    val_mask = data[out_node_type].val_mask\n",
    "    test_mask = data[out_node_type].test_mask\n",
    "    y = data[out_node_type].y\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.edge_index_dict)#[out_node_type].log_softmax(dim=-1)\n",
    "        loss = F.nll_loss(out[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss.item())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        out = model(data.x_dict, data.edge_index_dict)#[out_node_type].log_softmax(dim=-1)\n",
    "        pred = out.argmax(dim=-1)\n",
    "\n",
    "        accs = []\n",
    "        for mask in [train_mask, val_mask, test_mask]:\n",
    "            correct = (pred[mask] == y[mask]).sum()\n",
    "            accs.append(float(correct) / mask.sum().item())\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    times = []\n",
    "\n",
    "    for epoch in range(1, EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "\n",
    "        # Uncomment to see progress each epoch\n",
    "        print(f'Epoch: {epoch:04d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "              f'Test: {tmp_test_acc:.4f}, Final Test: {test_acc:.4f}')\n",
    "\n",
    "        times.append(time.time() - start)\n",
    "    return {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc\n",
    "    }, None\n",
    "\n",
    "def Train_SparseGraphTransformerModel(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data,\n",
    "              out_node_type):\n",
    "\n",
    "    OUT_DIM = len(data[out_node_type].y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = HeteroGNNModel(\n",
    "        data.metadata(),\n",
    "        SparseGraphTransformerModel,\n",
    "        in_feat_dims={node_type: data[node_type].x.shape[1] for node_type in data.metadata()[0]},\n",
    "        out_node_type=out_node_type,\n",
    "        hidden_dim=128,\n",
    "        out_dim=OUT_DIM,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        num_heads=NUM_HEADS,\n",
    "    ).to(device)\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_mask = data[out_node_type].train_mask\n",
    "    val_mask = data[out_node_type].val_mask\n",
    "    test_mask = data[out_node_type].test_mask\n",
    "    y = data[out_node_type].y\n",
    "    \n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.dense_adj)\n",
    "        loss = F.nll_loss(out[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss.item())\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        out = model(data.x_dict, data.dense_adj)\n",
    "        pred = out.argmax(dim=-1)\n",
    "\n",
    "        accs = []\n",
    "        for mask in [train_mask, val_mask, test_mask]:\n",
    "            correct = (pred[mask] == y[mask]).sum()\n",
    "            accs.append(float(correct) / mask.sum().item())\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    times = []\n",
    "\n",
    "    for epoch in range(1, EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "\n",
    "        # Uncomment to see progress each epoch\n",
    "        print(f'Epoch: {epoch:04d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "              f'Test: {tmp_test_acc:.4f}, Final Test: {test_acc:.4f}')\n",
    "\n",
    "        times.append(time.time() - start)\n",
    "        \n",
    "    return {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc\n",
    "    }, model.attn_weights_list\n",
    "\n",
    "def Train_DenseGraphTransformerModel(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data):\n",
    "\n",
    "    IN_DIM = data.x.shape[-1]\n",
    "    OUT_DIM = len(data.y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = DenseGraphTransformerModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.pos_enc)\n",
    "        out = model(data.x, data.pos_enc, data.dense_sp_matrix)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred, accs = model(data.x, data.pos_enc, data.dense_sp_matrix).argmax(dim=-1), []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(1, 100):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
    "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
    "        #       f'Final Test: {test_acc:.4f}')\n",
    "        times.append(time.time() - start)\n",
    "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
    "\n",
    "    # Notes\n",
    "    # - Dense Transformer needs to be trained for a bit longer to reach low loss value\n",
    "    # - Node positional encodings are not particularly useful\n",
    "    # - Edge distance encodings are very useful\n",
    "    # - Since Cora is highly homophilic, it is important to bias the attention towards nearby nodes\n",
    "\n",
    "def Train_DenseGraphTransformerModel_V2(NUM_LAYERS,\n",
    "              NUM_HEADS,\n",
    "              data):\n",
    "\n",
    "    IN_DIM = data.x.shape[-1]\n",
    "    OUT_DIM = len(data.y.unique())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = DenseGraphTransformerModel_V2(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.pos_enc, data.dense_sp_matrix)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred, accs = model(data.x, data.pos_enc, data.dense_sp_matrix).argmax(dim=-1), []\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "        return accs\n",
    "\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(1, 100):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
    "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
    "        #       f'Final Test: {test_acc:.4f}')\n",
    "        times.append(time.time() - start)\n",
    "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
    "\n",
    "    # Notes\n",
    "    # - Dense Transformer needs to be trained for a bit longer to reach low loss value\n",
    "    # - Node positional encodings are not particularly useful\n",
    "    # - Edge distance encodings are very useful\n",
    "    # - Since Cora is highly homophilic, it is important to bias the attention towards nearby nodes"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veDrDxJIaO7f"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3wGJPl3YJcd"
   },
   "source": [
    "## Training: 1 Layer, 1 Head"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229201,
     "status": "ok",
     "timestamp": 1710738973707,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "y6GoLurKW57q",
    "outputId": "5a2e6a7c-8104-4d38-cdff-fb422102fd9b",
    "ExecuteTime": {
     "end_time": "2025-03-24T04:38:30.632210Z",
     "start_time": "2025-03-24T04:38:18.963684Z"
    }
   },
   "source": [
    "import tqdm\n",
    "NUM_LAYERS = 3\n",
    "NUM_HEADS = 1\n",
    "# NUM_RUNS = 10\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    # TODO: incorporate multiple different splits?\n",
    "    # for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        \n",
    "    out_node_type = list(data.y_dict.keys())[0]\n",
    "\n",
    "    accuracy_statistics = {}\n",
    "    attn_weights = {}\n",
    "\n",
    "    accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data, out_node_type)\n",
    "    # accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data, out_node_type)\n",
    "    # # accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "    # accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "    # attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel']).cpu()\n",
    "    # # attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel']).cpu()\n",
    "    # attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\n",
    "    # run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "    all_stats[data_key] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "\n",
    "import pickle\n",
    "# with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_stats, f)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on IMDB\n",
      "Epoch: 0001, Loss: 7.3085, Train: 0.0750, Val: 0.0850, Test: 0.0707, Final Test: 0.0707\n",
      "Epoch: 0002, Loss: 5.4216, Train: 0.1125, Val: 0.0675, Test: 0.0610, Final Test: 0.0707\n",
      "Epoch: 0003, Loss: 4.8641, Train: 0.4425, Val: 0.2975, Test: 0.3051, Final Test: 0.3051\n",
      "Epoch: 0004, Loss: 4.6762, Train: 0.5650, Val: 0.3800, Test: 0.3870, Final Test: 0.3870\n",
      "Epoch: 0005, Loss: 4.4191, Train: 0.6125, Val: 0.3925, Test: 0.4057, Final Test: 0.4057\n",
      "Epoch: 0006, Loss: 4.3768, Train: 0.6525, Val: 0.4075, Test: 0.4166, Final Test: 0.4166\n",
      "Epoch: 0007, Loss: 4.2381, Train: 0.7350, Val: 0.4050, Test: 0.4436, Final Test: 0.4166\n",
      "Epoch: 0008, Loss: 4.0282, Train: 0.8125, Val: 0.4425, Test: 0.4687, Final Test: 0.4687\n",
      "Epoch: 0009, Loss: 4.0227, Train: 0.8400, Val: 0.4675, Test: 0.4885, Final Test: 0.4885\n",
      "Epoch: 0010, Loss: 4.0902, Train: 0.8700, Val: 0.4825, Test: 0.5000, Final Test: 0.5000\n",
      "Epoch: 0011, Loss: 4.0118, Train: 0.8825, Val: 0.4725, Test: 0.5072, Final Test: 0.5000\n",
      "Epoch: 0012, Loss: 3.8957, Train: 0.9000, Val: 0.4775, Test: 0.5101, Final Test: 0.5000\n",
      "Epoch: 0013, Loss: 3.8037, Train: 0.9200, Val: 0.4900, Test: 0.5141, Final Test: 0.5141\n",
      "Epoch: 0014, Loss: 3.6059, Train: 0.9325, Val: 0.4950, Test: 0.5144, Final Test: 0.5144\n",
      "Epoch: 0015, Loss: 3.5232, Train: 0.9300, Val: 0.5025, Test: 0.5066, Final Test: 0.5066\n",
      "Epoch: 0016, Loss: 3.6140, Train: 0.9375, Val: 0.5200, Test: 0.5017, Final Test: 0.5017\n",
      "Epoch: 0017, Loss: 3.3267, Train: 0.9375, Val: 0.5125, Test: 0.5009, Final Test: 0.5017\n",
      "Epoch: 0018, Loss: 3.5229, Train: 0.9375, Val: 0.5125, Test: 0.5006, Final Test: 0.5017\n",
      "Epoch: 0019, Loss: 3.4757, Train: 0.9400, Val: 0.5100, Test: 0.5035, Final Test: 0.5017\n",
      "Epoch: 0020, Loss: 3.5860, Train: 0.9425, Val: 0.5300, Test: 0.5115, Final Test: 0.5115\n",
      "Epoch: 0021, Loss: 3.3589, Train: 0.9475, Val: 0.5425, Test: 0.5204, Final Test: 0.5204\n",
      "Epoch: 0022, Loss: 3.3743, Train: 0.9600, Val: 0.5625, Test: 0.5345, Final Test: 0.5345\n",
      "Epoch: 0023, Loss: 3.2349, Train: 0.9650, Val: 0.5725, Test: 0.5466, Final Test: 0.5466\n",
      "Epoch: 0024, Loss: 3.5640, Train: 0.9700, Val: 0.5725, Test: 0.5535, Final Test: 0.5466\n",
      "Epoch: 0025, Loss: 3.1954, Train: 0.9700, Val: 0.5775, Test: 0.5630, Final Test: 0.5630\n",
      "Epoch: 0026, Loss: 3.0553, Train: 0.9750, Val: 0.5775, Test: 0.5676, Final Test: 0.5630\n",
      "Epoch: 0027, Loss: 3.2116, Train: 0.9750, Val: 0.5825, Test: 0.5684, Final Test: 0.5684\n",
      "Epoch: 0028, Loss: 3.1016, Train: 0.9775, Val: 0.5825, Test: 0.5707, Final Test: 0.5684\n",
      "Epoch: 0029, Loss: 3.0103, Train: 0.9825, Val: 0.5875, Test: 0.5664, Final Test: 0.5664\n",
      "Epoch: 0030, Loss: 3.1056, Train: 0.9850, Val: 0.5875, Test: 0.5638, Final Test: 0.5664\n",
      "Epoch: 0031, Loss: 3.0364, Train: 0.9900, Val: 0.5875, Test: 0.5618, Final Test: 0.5664\n",
      "Epoch: 0032, Loss: 2.8731, Train: 0.9900, Val: 0.5875, Test: 0.5624, Final Test: 0.5664\n",
      "Epoch: 0033, Loss: 2.8155, Train: 0.9900, Val: 0.5825, Test: 0.5635, Final Test: 0.5664\n",
      "Epoch: 0034, Loss: 3.0293, Train: 0.9875, Val: 0.6000, Test: 0.5633, Final Test: 0.5633\n",
      "Epoch: 0035, Loss: 3.0355, Train: 0.9875, Val: 0.5975, Test: 0.5644, Final Test: 0.5633\n",
      "Epoch: 0036, Loss: 2.7128, Train: 0.9875, Val: 0.5925, Test: 0.5653, Final Test: 0.5633\n",
      "Epoch: 0037, Loss: 2.8819, Train: 0.9875, Val: 0.5900, Test: 0.5650, Final Test: 0.5633\n",
      "Epoch: 0038, Loss: 2.9688, Train: 0.9900, Val: 0.5925, Test: 0.5673, Final Test: 0.5633\n",
      "Epoch: 0039, Loss: 2.9580, Train: 0.9900, Val: 0.5875, Test: 0.5679, Final Test: 0.5633\n",
      "Epoch: 0040, Loss: 2.7262, Train: 0.9925, Val: 0.5850, Test: 0.5716, Final Test: 0.5633\n",
      "Epoch: 0041, Loss: 2.7087, Train: 0.9925, Val: 0.5700, Test: 0.5796, Final Test: 0.5633\n",
      "Epoch: 0042, Loss: 2.6598, Train: 0.9925, Val: 0.5700, Test: 0.5791, Final Test: 0.5633\n",
      "Epoch: 0043, Loss: 2.7197, Train: 0.9950, Val: 0.5650, Test: 0.5788, Final Test: 0.5633\n",
      "Epoch: 0044, Loss: 2.6490, Train: 0.9950, Val: 0.5625, Test: 0.5773, Final Test: 0.5633\n",
      "Epoch: 0045, Loss: 2.5850, Train: 0.9950, Val: 0.5675, Test: 0.5765, Final Test: 0.5633\n",
      "Epoch: 0046, Loss: 2.5808, Train: 0.9925, Val: 0.5675, Test: 0.5736, Final Test: 0.5633\n",
      "Epoch: 0047, Loss: 2.6126, Train: 0.9925, Val: 0.5725, Test: 0.5722, Final Test: 0.5633\n",
      "Epoch: 0048, Loss: 2.4320, Train: 0.9950, Val: 0.5725, Test: 0.5713, Final Test: 0.5633\n",
      "Epoch: 0049, Loss: 2.5304, Train: 0.9950, Val: 0.5700, Test: 0.5719, Final Test: 0.5633\n",
      "Epoch: 0050, Loss: 2.4303, Train: 0.9975, Val: 0.5700, Test: 0.5748, Final Test: 0.5633\n",
      "Epoch: 0051, Loss: 2.5135, Train: 0.9975, Val: 0.5775, Test: 0.5739, Final Test: 0.5633\n",
      "Epoch: 0052, Loss: 2.7588, Train: 1.0000, Val: 0.5775, Test: 0.5722, Final Test: 0.5633\n",
      "Epoch: 0053, Loss: 2.4283, Train: 1.0000, Val: 0.5775, Test: 0.5650, Final Test: 0.5633\n",
      "Epoch: 0054, Loss: 2.6284, Train: 1.0000, Val: 0.5850, Test: 0.5644, Final Test: 0.5633\n",
      "Epoch: 0055, Loss: 2.5797, Train: 1.0000, Val: 0.5750, Test: 0.5664, Final Test: 0.5633\n",
      "Epoch: 0056, Loss: 2.6005, Train: 1.0000, Val: 0.5800, Test: 0.5690, Final Test: 0.5633\n",
      "Epoch: 0057, Loss: 2.5059, Train: 1.0000, Val: 0.5675, Test: 0.5713, Final Test: 0.5633\n",
      "Epoch: 0058, Loss: 2.5975, Train: 1.0000, Val: 0.5550, Test: 0.5750, Final Test: 0.5633\n",
      "Epoch: 0059, Loss: 2.3986, Train: 1.0000, Val: 0.5600, Test: 0.5745, Final Test: 0.5633\n",
      "Epoch: 0060, Loss: 2.4156, Train: 1.0000, Val: 0.5675, Test: 0.5785, Final Test: 0.5633\n",
      "Epoch: 0061, Loss: 2.5357, Train: 0.9975, Val: 0.5625, Test: 0.5730, Final Test: 0.5633\n",
      "Epoch: 0062, Loss: 2.6322, Train: 0.9975, Val: 0.5625, Test: 0.5725, Final Test: 0.5633\n",
      "Epoch: 0063, Loss: 2.4224, Train: 0.9975, Val: 0.5475, Test: 0.5707, Final Test: 0.5633\n",
      "Epoch: 0064, Loss: 2.4154, Train: 0.9975, Val: 0.5550, Test: 0.5664, Final Test: 0.5633\n",
      "Epoch: 0065, Loss: 2.4603, Train: 1.0000, Val: 0.5600, Test: 0.5676, Final Test: 0.5633\n",
      "Epoch: 0066, Loss: 2.6022, Train: 1.0000, Val: 0.5650, Test: 0.5673, Final Test: 0.5633\n",
      "Epoch: 0067, Loss: 2.4125, Train: 1.0000, Val: 0.5600, Test: 0.5679, Final Test: 0.5633\n",
      "Epoch: 0068, Loss: 2.3810, Train: 1.0000, Val: 0.5625, Test: 0.5667, Final Test: 0.5633\n",
      "Epoch: 0069, Loss: 2.2774, Train: 1.0000, Val: 0.5675, Test: 0.5670, Final Test: 0.5633\n",
      "Epoch: 0070, Loss: 2.4756, Train: 1.0000, Val: 0.5650, Test: 0.5679, Final Test: 0.5633\n",
      "Epoch: 0071, Loss: 2.3936, Train: 1.0000, Val: 0.5625, Test: 0.5707, Final Test: 0.5633\n",
      "Epoch: 0072, Loss: 2.1432, Train: 1.0000, Val: 0.5600, Test: 0.5745, Final Test: 0.5633\n",
      "Epoch: 0073, Loss: 2.2281, Train: 1.0000, Val: 0.5650, Test: 0.5768, Final Test: 0.5633\n",
      "Epoch: 0074, Loss: 2.6788, Train: 1.0000, Val: 0.5650, Test: 0.5779, Final Test: 0.5633\n",
      "Epoch: 0075, Loss: 2.3824, Train: 1.0000, Val: 0.5675, Test: 0.5768, Final Test: 0.5633\n",
      "Epoch: 0076, Loss: 2.4995, Train: 1.0000, Val: 0.5650, Test: 0.5768, Final Test: 0.5633\n",
      "Epoch: 0077, Loss: 2.3118, Train: 1.0000, Val: 0.5650, Test: 0.5765, Final Test: 0.5633\n",
      "Epoch: 0078, Loss: 2.3922, Train: 1.0000, Val: 0.5650, Test: 0.5768, Final Test: 0.5633\n",
      "Epoch: 0079, Loss: 2.3899, Train: 1.0000, Val: 0.5675, Test: 0.5773, Final Test: 0.5633\n",
      "Epoch: 0080, Loss: 2.3488, Train: 1.0000, Val: 0.5650, Test: 0.5779, Final Test: 0.5633\n",
      "Epoch: 0081, Loss: 2.3571, Train: 1.0000, Val: 0.5600, Test: 0.5776, Final Test: 0.5633\n",
      "Epoch: 0082, Loss: 2.3107, Train: 1.0000, Val: 0.5600, Test: 0.5768, Final Test: 0.5633\n",
      "Epoch: 0083, Loss: 2.4244, Train: 1.0000, Val: 0.5625, Test: 0.5750, Final Test: 0.5633\n",
      "Epoch: 0084, Loss: 2.3252, Train: 1.0000, Val: 0.5600, Test: 0.5745, Final Test: 0.5633\n",
      "Epoch: 0085, Loss: 2.3751, Train: 1.0000, Val: 0.5650, Test: 0.5730, Final Test: 0.5633\n",
      "Epoch: 0086, Loss: 2.4033, Train: 1.0000, Val: 0.5625, Test: 0.5702, Final Test: 0.5633\n",
      "Epoch: 0087, Loss: 2.3742, Train: 1.0000, Val: 0.5650, Test: 0.5667, Final Test: 0.5633\n",
      "Epoch: 0088, Loss: 2.4466, Train: 1.0000, Val: 0.5725, Test: 0.5664, Final Test: 0.5633\n",
      "Epoch: 0089, Loss: 2.2827, Train: 1.0000, Val: 0.5750, Test: 0.5656, Final Test: 0.5633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m     17\u001B[39m accuracy_statistics = {}\n\u001B[32m     18\u001B[39m attn_weights = {}\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m accuracy_statistics[\u001B[33m'\u001B[39m\u001B[33mGCN\u001B[39m\u001B[33m'\u001B[39m], attn_weights[\u001B[33m'\u001B[39m\u001B[33mGCN\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mTrain_GCN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mNUM_LAYERS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mNUM_HEADS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_node_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data, out_node_type)\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# # accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\u001B[39;00m\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m# run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\u001B[39;00m\n\u001B[32m     28\u001B[39m all_stats[data_key] = {\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m: accuracy_statistics, \u001B[33m'\u001B[39m\u001B[33mattentions\u001B[39m\u001B[33m'\u001B[39m: attn_weights}\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 63\u001B[39m, in \u001B[36mTrain_GCN\u001B[39m\u001B[34m(NUM_LAYERS, NUM_HEADS, data, out_node_type)\u001B[39m\n\u001B[32m     60\u001B[39m start = time.time()\n\u001B[32m     62\u001B[39m loss = train()\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m train_acc, val_acc, tmp_test_acc = \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m val_acc > best_val_acc:\n\u001B[32m     65\u001B[39m     best_val_acc = val_acc\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 46\u001B[39m, in \u001B[36mTrain_GCN.<locals>.test\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;129m@torch\u001B[39m.no_grad()\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtest\u001B[39m():\n\u001B[32m     45\u001B[39m     model.eval()\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     out = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mx_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43medge_index_dict\u001B[49m\u001B[43m)\u001B[49m[out_node_type].log_softmax(dim=-\u001B[32m1\u001B[39m)\n\u001B[32m     47\u001B[39m     pred = out.argmax(dim=-\u001B[32m1\u001B[39m)\n\u001B[32m     49\u001B[39m     accs = []\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch\\fx\\graph_module.py:822\u001B[39m, in \u001B[36mGraphModule.recompile.<locals>.call_wrapped\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    821\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_wrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m822\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_wrapped_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch\\fx\\graph_module.py:387\u001B[39m, in \u001B[36m_WrappedCall.__call__\u001B[39m\u001B[34m(self, obj, *args, **kwargs)\u001B[39m\n\u001B[32m    385\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cls_call(obj, *args, **kwargs)\n\u001B[32m    386\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m387\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m    388\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    389\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m e.__traceback__\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<eval_with_key>.12:51\u001B[39m, in \u001B[36mforward\u001B[39m\u001B[34m(self, x, edge_index)\u001B[39m\n\u001B[32m     49\u001B[39m layers_2__movie = torch.add(layers_2__movie1, layers_2__movie2);  layers_2__movie1 = layers_2__movie2 = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     50\u001B[39m relu_2__movie = torch.nn.functional.relu(layers_2__movie, inplace = \u001B[38;5;28;01mFalse\u001B[39;00m);  layers_2__movie = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m relu_2__director = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfunctional\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayers_2__director\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m;  layers_2__director = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     52\u001B[39m relu_2__actor = torch.nn.functional.relu(layers_2__actor, inplace = \u001B[38;5;28;01mFalse\u001B[39;00m);  layers_2__actor = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     53\u001B[39m dropout_2__movie = \u001B[38;5;28mself\u001B[39m.dropout.movie(relu_2__movie);  relu_2__movie = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\Graph_Attention_Interpretability\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1704\u001B[39m, in \u001B[36mrelu\u001B[39m\u001B[34m(input, inplace)\u001B[39m\n\u001B[32m   1702\u001B[39m     result = torch.relu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m   1703\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1704\u001B[39m     result = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1705\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxj1ye0Y1ZwC"
   },
   "source": [
    "## Training: 1 Layer, 2 Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350257,
     "status": "ok",
     "timestamp": 1710739323962,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "1igyz0Pr1dRN",
    "outputId": "007dcfb4-f029-465a-81fe-05b0ac2fb881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:32<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:24<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:52<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:19<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:18<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "NUM_LAYERS = 1\n",
    "NUM_HEADS = 2\n",
    "NUM_RUNS = 10\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        # accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel']).cpu()\n",
    "        # attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWeKuQTt1k_M"
   },
   "source": [
    "## Training: 2 Layers, 1 Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393297,
     "status": "ok",
     "timestamp": 1710739717256,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "zcAfw7My1oij",
    "outputId": "9a14a337-b5e8-458a-8573-4ce8a7a50711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:29<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:33<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:56<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:27<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "### Train Cora ###\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 1\n",
    "NUM_RUNS = 10\n",
    "# data_key = 'Wisconsin'\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        # accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel'])\n",
    "        # attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel'])\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2'])\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hMUb2yK1pEB"
   },
   "source": [
    "## Training: 2 Layers, 2 Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 643061,
     "status": "ok",
     "timestamp": 1710740360315,
     "user": {
      "displayName": "Batu El",
      "userId": "11666366648103508022"
     },
     "user_tz": 0
    },
    "id": "YYmZVaET1sKD",
    "outputId": "e7aec9f4-9e13-4f97-f939-e114ca8fc868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:48<00:00,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:58<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Chameleon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:42<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Squirrel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [01:35<00:00,  9.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Cornell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:30<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Texas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:29<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Wisconsin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:30<00:00,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import tqdm\n",
    "### Train Cora ###\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 2\n",
    "NUM_RUNS = 10\n",
    "# data_key = 'Wisconsin'\n",
    "all_stats = {}\n",
    "for data_key in DATASETS:\n",
    "    print(f'Training on {data_key}')\n",
    "    data = DATASETS[data_key]\n",
    "\n",
    "    TRAIN_MASKS = data.train_mask\n",
    "    VAL_MASKS = data.val_mask\n",
    "    TEST_MASKS = data.test_mask\n",
    "\n",
    "    run_stats = {}\n",
    "\n",
    "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
    "        gc.collect()\n",
    "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
    "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
    "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
    "\n",
    "        accuracy_statistics = {}\n",
    "        attn_weights = {}\n",
    "\n",
    "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        # accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
    "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
    "        attn_weights['SparseGraphTransformerModel'] = torch.stack(attn_weights['SparseGraphTransformerModel']).cpu()\n",
    "        # attn_weights['DenseGraphTransformerModel'] = torch.stack(attn_weights['DenseGraphTransformerModel']).cpu()\n",
    "        attn_weights['DenseGraphTransformerModel_V2'] = torch.stack(attn_weights['DenseGraphTransformerModel_V2']).cpu()\n",
    "        run_stats[mask_idx] = {'accuracy': accuracy_statistics, 'attentions': attn_weights}\n",
    "\n",
    "    all_stats[data_key] = run_stats\n",
    "    data.train_mask = TRAIN_MASKS\n",
    "    data.val_mask = VAL_MASKS\n",
    "    data.test_mask = TEST_MASKS\n",
    "\n",
    "import pickle\n",
    "with open('drive/MyDrive/Colab Notebooks/L65_Project/' + f'all_stats_{NUM_LAYERS}L_{NUM_HEADS}H.pkl', 'wb') as f:\n",
    "    pickle.dump(all_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXuPgGbGa2Nd"
   },
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "670dtom5sl10"
   },
   "source": [
    "## Table 2: Accuracy Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNkbWu7zH06U"
   },
   "outputs": [],
   "source": [
    "### Table 2 ###\n",
    "### Accuracy Statistics ###\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "all_stats_df = {}\n",
    "for data_key in all_stats:\n",
    "  run_stats = all_stats[data_key]\n",
    "  table1 = pd.concat({key : pd.DataFrame(run_stats[key]['accuracy']) for key in run_stats}, axis=0)\n",
    "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
    "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
    "  # table1 = pd.concat({'Train': table1_train, 'Test': table1_test}, axis=1)\n",
    "  table1 = table1_test\n",
    "  all_stats_df[data_key] = table1\n",
    "pd.concat(all_stats_df, axis=1).round(2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM7QF060g8m/oZks22EC8jM",
   "collapsed_sections": [
    "Fxj1ye0Y1ZwC",
    "sWeKuQTt1k_M",
    "2hMUb2yK1pEB",
    "ZXuPgGbGa2Nd",
    "670dtom5sl10"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1nYy2OQQ4os8qAJRaYQ2kwsbNjzw3zFyx",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
